{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNx70674XZd0Eu+y5U9tnw+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JWiseman-git/ml_sandbox/blob/main/token_classifier_revisited.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mDA4NF2isZR",
        "outputId": "386a4abd-e97c-4c7d-ebb3-9849932c204e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[11227   128  6280 ...   185  1671   323]\n",
            " [    0     0     0 ...  4528  1699     9]\n",
            " [ 3544  1132   508 ...  6749   368  8604]\n",
            " ...\n",
            " [  920   810   746 ...   660  3692   617]\n",
            " [    0     0     0 ...   823  1308 28473]\n",
            " [  328 13572  2082 ...  6873  6127    69]]\n",
            "Original X_train shape: (315, 500)\n",
            "[[[ 3830   747   721 ...   236  8390 23023]]\n",
            "\n",
            " [[  213  1809    67 ...   505   224   330]]\n",
            "\n",
            " [[   19  9924    24 ...  4145  1404   307]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[14942   169  7274 ...  2246  1058   453]]\n",
            "\n",
            " [[ 1096  1065    11 ...   135  1392   176]]\n",
            "\n",
            " [[  799   542  1849 ...   296  2157   170]]]\n",
            "Reshaped X_train_lstm shape: (315, 1, 500)\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import numpy as np\n",
        "import tqdm\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Input\n",
        "# from tensorflow.keras.layers import Embedding # Removed as it's not suitable for this data type\n",
        "\n",
        "url = 'https://nordy.cloud/dataset_lstm.npy'\n",
        "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
        "result = requests.get(url, headers=headers)\n",
        "\n",
        "npzfile = np.load(BytesIO(result.content))\n",
        "X_train = npzfile['X_train']\n",
        "print(X_train)\n",
        "X_test = npzfile['X_test']\n",
        "y_train = npzfile['y_train']\n",
        "y_test = npzfile['y_test']\n",
        "\n",
        "print(f\"Original X_train shape: {X_train.shape}\")\n",
        "\n",
        "# Define the number of features you want to use\n",
        "limited_features_count = X_train.shape[1] # Using all features available\n",
        "\n",
        "# # Ensure limited_features_count does not exceed the actual number of features\n",
        "# if limited_features_count > X_train.shape[1]:\n",
        "#     limited_features_count = X_train.shape[1]\n",
        "#     print(f\"Warning: limited_features_count was greater than actual features. Using all {limited_features_count} features.\")\n",
        "\n",
        "# Select the first 'limited_features_count' features\n",
        "X_train_limited = X_train[:, :limited_features_count]\n",
        "X_test_limited = X_test[:, :limited_features_count]\n",
        "\n",
        "number_of_features = limited_features_count\n",
        "# sequence_length = 1 # Assuming sequence length of 1 based on previous commented reshaping\n",
        "\n",
        "# Reshape the limited feature datasets\n",
        "X_train_lstm = np.reshape(X_train_limited, (X_train_limited.shape[0], sequence_length, number_of_features))\n",
        "X_test_lstm = np.reshape(X_test_limited, (X_test_limited.shape[0], sequence_length, number_of_features))\n",
        "\n",
        "print(X_test_lstm)\n",
        "\n",
        "y_train_lstm = y_train.reshape(-1, 1)\n",
        "y_test_lstm = y_test.reshape(-1, 1)\n",
        "\n",
        "print(f\"Reshaped X_train_lstm shape: {X_train_lstm.shape}\")\n",
        "\n",
        "# model = Sequential([\n",
        "#     Input(shape=(sequence_length, number_of_features)), # Corrected Input shape for LSTM\n",
        "#     LSTM(64),\n",
        "#     Dense(1, activation='sigmoid')\n",
        "# ])\n",
        "\n",
        "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# # Now you can fit the model with the limited features\n",
        "# model.fit(X_train_lstm, y_train_lstm, epochs=5, batch_size=50, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"LSTM text classifier with proper sequence handling and Embedding layer.\"\"\"\n",
        "\n",
        "from io import BytesIO\n",
        "\n",
        "import numpy as np\n",
        "import requests\n",
        "from tensorflow.keras.layers import Bidirectional, Dense, Dropout, Embedding, LSTM\n",
        "from tensorflow.keras.metrics import AUC, BinaryAccuracy, Precision, Recall\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# --- Configuration ---\n",
        "VOCAB_SIZE = 30000  # Must be >= max token ID in dataset + 1\n",
        "EMBEDDING_DIM = 128\n",
        "LSTM_UNITS = 128\n",
        "DROPOUT = 0.3\n",
        "EPOCHS = 30  # Loss was still dropping at epoch 5 — give it more room\n",
        "BATCH_SIZE = 32\n",
        "VALIDATION_SPLIT = 0.2\n",
        "\n",
        "# --- Load dataset ---\n",
        "url = \"https://nordy.cloud/dataset_lstm.npy\"\n",
        "headers = {\n",
        "    \"User-Agent\": (\n",
        "        \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) \"\n",
        "        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
        "        \"Chrome/50.0.2661.102 Safari/537.36\"\n",
        "    ),\n",
        "}\n",
        "result = requests.get(url, headers=headers, timeout=30)\n",
        "npzfile = np.load(BytesIO(result.content))\n",
        "\n",
        "X_train = npzfile[\"X_train\"]\n",
        "X_test = npzfile[\"X_test\"]\n",
        "y_train = npzfile[\"y_train\"]\n",
        "y_test = npzfile[\"y_test\"]\n",
        "\n",
        "# --- Inspect shapes ---\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"X_test shape:  {X_test.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"y_test shape:  {y_test.shape}\")\n",
        "print(f\"Max token ID:  {X_train.max()}\")\n",
        "\n",
        "# --- Validate sample counts match ---\n",
        "assert X_train.shape[0] == y_train.shape[0], \"X_train and y_train sample count mismatch\"\n",
        "assert X_test.shape[0] == y_test.shape[0], \"X_test and y_test sample count mismatch\"\n",
        "\n",
        "# --- Determine dimensions ---\n",
        "# Each row IS a sequence of tokens — sequence_length = number of columns\n",
        "sequence_length = X_train.shape[1]\n",
        "\n",
        "# Ensure vocab_size covers all token IDs\n",
        "vocab_size = max(VOCAB_SIZE, int(X_train.max()) + 1)\n",
        "\n",
        "# --- Determine number of labels ---\n",
        "num_labels = y_train.shape[1]  # 39 labels\n",
        "print(f\"Number of labels: {num_labels}\")\n",
        "\n",
        "# --- Build model ---\n",
        "# Multi-label classification: each of the 39 outputs is an independent binary\n",
        "# decision, so we use sigmoid (not softmax) and binary_crossentropy.\n",
        "#\n",
        "# Improvements over the basic version:\n",
        "# - Bidirectional LSTM: reads the sequence forwards AND backwards\n",
        "# - Dropout: reduces overfitting on this small dataset (315 samples)\n",
        "# - Larger embedding/LSTM dims: more capacity to learn token relationships\n",
        "model = Sequential(\n",
        "    [\n",
        "        Embedding(input_dim=vocab_size, output_dim=EMBEDDING_DIM),\n",
        "        Bidirectional(LSTM(LSTM_UNITS)),\n",
        "        Dropout(DROPOUT),\n",
        "        Dense(64, activation=\"relu\"),\n",
        "        Dropout(DROPOUT),\n",
        "        Dense(num_labels, activation=\"sigmoid\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Use metrics that actually make sense for multi-label:\n",
        "# - BinaryAccuracy: average per-label accuracy (is each label right?)\n",
        "# - Precision/Recall: how many predicted labels are correct / how many true labels are found\n",
        "# - AUC: overall ranking quality across thresholds\n",
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\n",
        "        BinaryAccuracy(name=\"binary_acc\"),\n",
        "        Precision(name=\"precision\"),\n",
        "        Recall(name=\"recall\"),\n",
        "        AUC(name=\"auc\", multi_label=True),\n",
        "    ],\n",
        ")\n",
        "model.summary()\n",
        "\n",
        "# --- Train ---\n",
        "model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    validation_split=VALIDATION_SPLIT,\n",
        ")\n",
        "\n",
        "# --- Evaluate ---\n",
        "results = model.evaluate(X_test, y_test)\n",
        "metric_names = model.metrics_names\n",
        "for name, value in zip(metric_names, results):\n",
        "    print(f\"  {name}: {value:.4f}\")\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# WHY MULTI-LABEL (NOT MULTI-CLASS)?\n",
        "# ============================================================================\n",
        "# y_train has shape (315, 39) — each sample has 39 independent binary labels.\n",
        "# This means a document can belong to MULTIPLE categories at once.\n",
        "#\n",
        "# - sigmoid: each output is an independent probability (0 to 1)\n",
        "# - binary_crossentropy: treats each of the 39 outputs as a separate binary task\n",
        "#\n",
        "# If instead each sample had exactly ONE class (mutually exclusive), you'd use:\n",
        "#   Dense(num_classes, activation=\"softmax\")\n",
        "#   loss=\"categorical_crossentropy\"\n",
        "# ============================================================================"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "R__ALaxxxYDy",
        "outputId": "833c98aa-541d-4d60-c815-b83e72f0467e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (315, 500)\n",
            "X_test shape:  (35, 500)\n",
            "y_train shape: (315, 39)\n",
            "y_test shape:  (35, 39)\n",
            "Max token ID:  28487\n",
            "Number of labels: 39\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - auc: 0.4855 - binary_acc: 0.6783 - loss: 0.6875 - precision: 0.0296 - recall: 0.3641 - val_auc: 0.4106 - val_binary_acc: 0.9007 - val_loss: 0.6439 - val_precision: 0.0160 - val_recall: 0.0476\n",
            "Epoch 2/30\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - auc: 0.4321 - binary_acc: 0.8678 - loss: 0.5322 - precision: 0.0336 - recall: 0.1505 - val_auc: 0.4233 - val_binary_acc: 0.9630 - val_loss: 0.1868 - val_precision: 0.0333 - val_recall: 0.0159\n",
            "Epoch 3/30\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - auc: 0.4400 - binary_acc: 0.9259 - loss: 0.2255 - precision: 0.0275 - recall: 0.0577 - val_auc: 0.4153 - val_binary_acc: 0.9744 - val_loss: 0.1326 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 4/30\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - auc: 0.4971 - binary_acc: 0.9650 - loss: 0.1658 - precision: 0.0592 - recall: 0.0243 - val_auc: 0.4115 - val_binary_acc: 0.9744 - val_loss: 0.1278 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 5/30\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - auc: 0.4438 - binary_acc: 0.9659 - loss: 0.1626 - precision: 0.0379 - recall: 0.0108 - val_auc: 0.4188 - val_binary_acc: 0.9744 - val_loss: 0.1259 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 6/30\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - auc: 0.4270 - binary_acc: 0.9681 - loss: 0.1569 - precision: 0.0332 - recall: 0.0099 - val_auc: 0.4330 - val_binary_acc: 0.9744 - val_loss: 0.1227 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 7/30\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - auc: 0.4581 - binary_acc: 0.9721 - loss: 0.1431 - precision: 0.0716 - recall: 0.0078 - val_auc: 0.4343 - val_binary_acc: 0.9744 - val_loss: 0.1209 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 8/30\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - auc: 0.4253 - binary_acc: 0.9718 - loss: 0.1470 - precision: 0.0369 - recall: 0.0035 - val_auc: 0.4260 - val_binary_acc: 0.9744 - val_loss: 0.1212 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 9/30\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - auc: 0.4690 - binary_acc: 0.9733 - loss: 0.1421 - precision: 0.0431 - recall: 0.0027 - val_auc: 0.4165 - val_binary_acc: 0.9744 - val_loss: 0.1218 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 10/30\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - auc: 0.4516 - binary_acc: 0.9735 - loss: 0.1397 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_auc: 0.4244 - val_binary_acc: 0.9744 - val_loss: 0.1217 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 11/30\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - auc: 0.4521 - binary_acc: 0.9729 - loss: 0.1377 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_auc: 0.4090 - val_binary_acc: 0.9744 - val_loss: 0.1210 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 12/30\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - auc: 0.4427 - binary_acc: 0.9728 - loss: 0.1420 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_auc: 0.4196 - val_binary_acc: 0.9744 - val_loss: 0.1210 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 13/30\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - auc: 0.4361 - binary_acc: 0.9738 - loss: 0.1373 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_auc: 0.3997 - val_binary_acc: 0.9744 - val_loss: 0.1200 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 14/30\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - auc: 0.4526 - binary_acc: 0.9741 - loss: 0.1353 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_auc: 0.4228 - val_binary_acc: 0.9744 - val_loss: 0.1206 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 15/30\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - auc: 0.4509 - binary_acc: 0.9740 - loss: 0.1342 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_auc: 0.4390 - val_binary_acc: 0.9744 - val_loss: 0.1203 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 16/30\n",
            "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 1s/step - auc: 0.4459 - binary_acc: 0.9742 - loss: 0.1301 - precision: 0.0000e+00 - recall: 0.0000e+00"
          ]
        }
      ]
    }
  ]
}