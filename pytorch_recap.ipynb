{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPHlpicbjTxJ4lInmLtm/Qm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JWiseman-git/ml_sandbox/blob/main/pytorch_recap.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YWPx1TVC_Y6k"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensor - i x j x k - $T_{ijk}$\n",
        "\n",
        "Reductive - higher order matrics\n",
        "\n",
        "independent of underlying coordinate system\n"
      ],
      "metadata": {
        "id": "RERDZjQbDlU1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scalar = torch.tensor(3)\n",
        "scalar.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJ_GqSgtGXl_",
        "outputId": "ffff5414-ce0b-4ab7-b287-8bb6190716ac"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector = torch.tensor([1,2])\n",
        "vector.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PhBiZ7lGxrM",
        "outputId": "00ff9b99-ed37-4d57-cdb3-fd88759d056e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matrix = torch.tensor([[[1, 2, 3],\n",
        "                        [3, 6, 9],\n",
        "                        [2, 4, 5]]])\n",
        "matrix.shape\n",
        "\n",
        "# torch.size([0,1,2]) -> first, second and third dims"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDFGmhRCG27b",
        "outputId": "99918c30-630f-4d01-a092-512d0f17f6b0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_tensor = torch.rand(3, 4)\n",
        "random_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-8l4brJH7Np",
        "outputId": "88329477-c2e7-430f-e5aa-a757f180da52"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1053, 0.2695, 0.3588, 0.1994],\n",
              "        [0.5472, 0.0062, 0.9516, 0.0753],\n",
              "        [0.8860, 0.5832, 0.3376, 0.8090]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a random tensor of size (224, 224, 3)\n",
        "random_image_size_tensor = torch.rand(size=(224, 224, 3))\n",
        "random_image_size_tensor.shape, random_image_size_tensor.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7e4S6DjIZWi",
        "outputId": "798f33d4-2359-48fb-d656-134f1216af00"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([224, 224, 3]), 3)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#torch zeros - useful for masking purposes\n",
        "zeros = torch.zeros(size=(3, 4))\n",
        "zeros, zeros.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-JvFC-ZIkxz",
        "outputId": "76ef130e-5328-40d4-a3c7-dd2cfc343f67"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.]]),\n",
              " torch.float32)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Floating point value used to indicate the precision to which a value is calculated - influencing the amount of data used to represent it\n",
        "- Tensors are initialised with a specific device allocated to specify the hardware for memory.\n",
        "- VRAM used by GPU and RAM used by CPU\n",
        "- Specifying device at the start of a script:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "import torch\n",
        "\n",
        "# 1. Check for GPU (CUDA) or Apple Silicon (MPS)\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = torch.device(\"mps\") # For Mac M1/M2/M3 chips\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# 2. Use the 'device' variable for all future initializations\n",
        "data = torch.ones((3, 3), device=device)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "EDUCX8qJKYDr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "float_16_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
        "                               dtype=torch.float16) # torch.half would also work\n",
        "\n",
        "float_16_tensor.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5y-B-XgK8Ag",
        "outputId": "67c6c9d1-61ff-4ce1-e3d3-e5acf65f90da"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float16"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basic Operations\n",
        "\n",
        "- inner dimensions of a matrix must match to allow for multiplication\n",
        "- for example (3, 2) @ (2, 3)\n",
        "\n",
        "The Dimensional Rule\n",
        "\n",
        "If Matrix $A$ has dimensions $(m \\times n)$ and Matrix $B$ has dimensions $(p \\times q)$, they can only be multiplied if:$$n = p$$The resulting matrix will have the dimensions $(m \\times q)$.\n",
        "\n",
        "When are Transposed Matrices used?\n",
        "\n",
        "While it isn't a\n",
        " requirement, there are specific scenarios where you multiply a matrix by its transpose ($A \\times A^T$ or $A^T \\times A$):"
      ],
      "metadata": {
        "id": "toxE5aWWLmWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#matric multiplication\n",
        "\n",
        "torch = torch.matmul(torch.rand(3, 2), torch.rand(2, 3))\n",
        "torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIrw3SgsNHG2",
        "outputId": "8da599da-33fe-4c3a-9d55-87851c90bd34"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2055, 0.5883, 1.0170],\n",
              "        [0.5719, 1.3500, 1.2323],\n",
              "        [0.4267, 0.9260, 0.4668]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Shapes need to be in the right way\n",
        "tensor_A = torch.tensor([[1, 2],\n",
        "                         [3, 4],\n",
        "                         [5, 6]], dtype=torch.float32)\n",
        "\n",
        "tensor_B = torch.tensor([[7, 10],\n",
        "                         [8, 11],\n",
        "                         [9, 12]], dtype=torch.float32)\n",
        "\n",
        "# The operation works when tensor_B is transposed\n",
        "print(f\"Original shapes: tensor_A = {tensor_A.shape}, tensor_B = {tensor_B.shape}\\n\")\n",
        "print(f\"New shapes: tensor_A = {tensor_A.shape} (same as above), tensor_B.T = {tensor_B.T.shape}\\n\")\n",
        "print(f\"Multiplying: {tensor_A.shape} * {tensor_B.T.shape} <- inner dimensions match\\n\")\n",
        "print(\"Output:\\n\")\n",
        "output = torch.matmul(tensor_A, tensor_B.T)\n",
        "print(output)\n",
        "print(f\"\\nOutput shape: {output.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oa1Wu3iUR4yF",
        "outputId": "740aac4d-a9ba-4c4a-b2c2-c26af7b3dbec"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original shapes: tensor_A = torch.Size([3, 2]), tensor_B = torch.Size([3, 2])\n",
            "\n",
            "New shapes: tensor_A = torch.Size([3, 2]) (same as above), tensor_B.T = torch.Size([2, 3])\n",
            "\n",
            "Multiplying: torch.Size([3, 2]) * torch.Size([2, 3]) <- inner dimensions match\n",
            "\n",
            "Output:\n",
            "\n",
            "tensor([[ 27.,  30.,  33.],\n",
            "        [ 61.,  68.,  75.],\n",
            "        [ 95., 106., 117.]])\n",
            "\n",
            "Output shape: torch.Size([3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.mm is a shortcut for matmul\n",
        "torch.mm(tensor_A, tensor_B.T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BK0rR5hhSPtX",
        "outputId": "490f055f-69e3-4467-b15c-3020218bf032"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 27.,  30.,  33.],\n",
              "        [ 61.,  68.,  75.],\n",
              "        [ 95., 106., 117.]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Feed-forward layer implements several matrix multiplication steps\n",
        "- Fully connected/dense layer - every neuron connects to every neuron in the previous layer"
      ],
      "metadata": {
        "id": "Nfa7vb7MS64G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.manual_seed(42)\n",
        "# randomly seed the weights of the matrix\n",
        "# implements a matrix multiplication between an input x and a Weights matrix A\n",
        "linear = torch.nn.Linear(in_features=2, # in_features = matches inner dimension of input\n",
        "                         out_features=6) # out_features = describes outer value\n",
        "x = tensor_A\n",
        "output = linear(x)\n",
        "print(f\"Input shape: {x.shape}\\n\")\n",
        "print(f\"Output:\\n{output}\\n\\nOutput shape: {output.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knlc9fLcS_zI",
        "outputId": "0254d5a7-4663-456b-f2d5-ff888dcc0cbc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([3, 2])\n",
            "\n",
            "Output:\n",
            "tensor([[2.2368, 1.2292, 0.4714, 0.3864, 0.1309, 0.9838],\n",
            "        [4.4919, 2.1970, 0.4469, 0.5285, 0.3401, 2.4777],\n",
            "        [6.7469, 3.1648, 0.4224, 0.6705, 0.5493, 3.9716]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "\n",
            "Output shape: torch.Size([3, 6])\n"
          ]
        }
      ]
    }
  ]
}