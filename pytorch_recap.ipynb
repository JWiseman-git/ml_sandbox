{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMlLElu57XDyXffkEb70ko/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JWiseman-git/ml_sandbox/blob/main/pytorch_recap.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "YWPx1TVC_Y6k"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensor - i x j x k - $T_{ijk}$\n",
        "\n",
        "Reductive - higher order matrics\n",
        "\n",
        "independent of underlying coordinate system\n"
      ],
      "metadata": {
        "id": "RERDZjQbDlU1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scalar = torch.tensor(3)\n",
        "scalar.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJ_GqSgtGXl_",
        "outputId": "eae53774-9ec0-4a1b-8be9-d71b5ee12dc2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector = torch.tensor([1,2])\n",
        "vector.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PhBiZ7lGxrM",
        "outputId": "21df4caf-ec24-4e16-dc10-24c6827bd631"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matrix = torch.tensor([[[1, 2, 3],\n",
        "                        [3, 6, 9],\n",
        "                        [2, 4, 5]]])\n",
        "matrix.shape\n",
        "\n",
        "# torch.size([0,1,2]) -> first, second and third dims"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDFGmhRCG27b",
        "outputId": "beec34f7-1ce4-4a5d-f1ff-c5888f42de4d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_tensor = torch.rand(3, 4)\n",
        "random_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-8l4brJH7Np",
        "outputId": "3adbaa1a-b099-44ac-9ba0-00b7976a93f8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3333, 0.4895, 0.0258, 0.4636],\n",
              "        [0.9161, 0.5211, 0.0817, 0.5078],\n",
              "        [0.7069, 0.4312, 0.9923, 0.1845]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a random tensor of size (224, 224, 3)\n",
        "random_image_size_tensor = torch.rand(size=(224, 224, 3))\n",
        "random_image_size_tensor.shape, random_image_size_tensor.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7e4S6DjIZWi",
        "outputId": "93cceae9-fb6c-41ee-a928-34b8ccc6e2ee"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([224, 224, 3]), 3)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#torch zeros - useful for masking purposes\n",
        "zeros = torch.zeros(size=(3, 4))\n",
        "zeros, zeros.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-JvFC-ZIkxz",
        "outputId": "43df85eb-3988-4482-d6e6-67ba53746881"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.]]),\n",
              " torch.float32)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Floating point value used to indicate the precision to which a value is calculated - influencing the amount of data used to represent it\n",
        "- Tensors are initialised with a specific device allocated to specify the hardware for memory.\n",
        "- VRAM used by GPU and RAM used by CPU\n",
        "- Specifying device at the start of a script:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "import torch\n",
        "\n",
        "# 1. Check for GPU (CUDA) or Apple Silicon (MPS)\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = torch.device(\"mps\") # For Mac M1/M2/M3 chips\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# 2. Use the 'device' variable for all future initializations\n",
        "data = torch.ones((3, 3), device=device)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "EDUCX8qJKYDr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "float_16_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
        "                               dtype=torch.float16) # torch.half would also work\n",
        "\n",
        "float_16_tensor.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5y-B-XgK8Ag",
        "outputId": "dfdfa50a-0870-4a45-b1c9-0b4a9a2e102c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float16"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basic Operations\n",
        "\n",
        "- inner dimensions of a matrix must match to allow for multiplication\n",
        "- for example (3, 2) @ (2, 3)\n",
        "\n",
        "The Dimensional Rule\n",
        "\n",
        "If Matrix $A$ has dimensions $(m \\times n)$ and Matrix $B$ has dimensions $(p \\times q)$, they can only be multiplied if:$$n = p$$The resulting matrix will have the dimensions $(m \\times q)$.\n",
        "\n",
        "When are Transposed Matrices used?\n",
        "\n",
        "While it isn't a\n",
        " requirement, there are specific scenarios where you multiply a matrix by its transpose ($A \\times A^T$ or $A^T \\times A$):"
      ],
      "metadata": {
        "id": "toxE5aWWLmWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#matric multiplication\n",
        "\n",
        "torch = torch.matmul(torch.rand(3, 2), torch.rand(2, 3))\n",
        "torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIrw3SgsNHG2",
        "outputId": "1aebf9e5-2595-40cd-ed58-a69f822e911f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3754, 0.5306, 0.0209],\n",
              "        [0.8812, 0.8254, 0.6017],\n",
              "        [1.1561, 1.0626, 0.8161]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shapes need to be in the right way\n",
        "tensor_A = torch.tensor([[1, 2],\n",
        "                         [3, 4],\n",
        "                         [5, 6]], dtype=torch.float32)\n",
        "\n",
        "tensor_B = torch.tensor([[7, 10],\n",
        "                         [8, 11],\n",
        "                         [9, 12]], dtype=torch.float32)\n",
        "\n",
        "# The operation works when tensor_B is transposed\n",
        "print(f\"Original shapes: tensor_A = {tensor_A.shape}, tensor_B = {tensor_B.shape}\\n\")\n",
        "print(f\"New shapes: tensor_A = {tensor_A.shape} (same as above), tensor_B.T = {tensor_B.T.shape}\\n\")\n",
        "print(f\"Multiplying: {tensor_A.shape} * {tensor_B.T.shape} <- inner dimensions match\\n\")\n",
        "print(\"Output:\\n\")\n",
        "output = torch.matmul(tensor_A, tensor_B.T)\n",
        "print(output)\n",
        "print(f\"\\nOutput shape: {output.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oa1Wu3iUR4yF",
        "outputId": "0087e469-70d6-4306-9f04-ded053e4cec8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original shapes: tensor_A = torch.Size([3, 2]), tensor_B = torch.Size([3, 2])\n",
            "\n",
            "New shapes: tensor_A = torch.Size([3, 2]) (same as above), tensor_B.T = torch.Size([2, 3])\n",
            "\n",
            "Multiplying: torch.Size([3, 2]) * torch.Size([2, 3]) <- inner dimensions match\n",
            "\n",
            "Output:\n",
            "\n",
            "tensor([[ 27.,  30.,  33.],\n",
            "        [ 61.,  68.,  75.],\n",
            "        [ 95., 106., 117.]])\n",
            "\n",
            "Output shape: torch.Size([3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.mm is a shortcut for matmul\n",
        "torch.mm(tensor_A, tensor_B.T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BK0rR5hhSPtX",
        "outputId": "769f42f4-1028-4b83-cb88-e989d3427b6a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 27.,  30.,  33.],\n",
              "        [ 61.,  68.,  75.],\n",
              "        [ 95., 106., 117.]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Feed-forward layer implements several matrix multiplication steps\n",
        "- Fully connected/dense layer - every neuron connects to every neuron in the previous layer"
      ],
      "metadata": {
        "id": "Nfa7vb7MS64G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "# randomly seed the weights of the matrix\n",
        "# implements a matrix multiplication between an input x and a Weights matrix A\n",
        "linear = torch.nn.Linear(in_features=3, # in_features = matches inner dimension of input\n",
        "                         out_features=6) # out_features = describes outer value\n",
        "x = tensor_A\n",
        "output = linear(x)\n",
        "print(f\"Input shape: {x.shape}\\n\")\n",
        "print(f\"Output:\\n{output}\\n\\nOutput shape: {output.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "knlc9fLcS_zI",
        "outputId": "063bb358-1ff3-42dd-f54e-e2763e5d9997"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-676759208.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# implements a matrix multiplication between an input x and a Weights matrix A\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m linear = torch.nn.Linear(in_features=3, # in_features = matches inner dimension of input \n\u001b[1;32m      5\u001b[0m                          out_features=6) # out_features = describes outer value \n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    }
  ]
}